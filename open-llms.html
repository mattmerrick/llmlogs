
<!DOCTYPE html>
<html lang="en">
<head>
<!-- Google Tag Manager -->
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-P33Z79C6');</script>
<!-- End Google Tag Manager -->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Complete Guide to Open Source LLMs (2025) - Parameters, Context Length & Try-Out Links</title>
    <meta name="description" content="Comprehensive guide to open-source Large Language Models (LLMs). Explore 60+ open LLMs with their parameters, context lengths, and try-out links. Updated January 2025.">
    
    <!-- Bootstrap CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet">
    
    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    
    <style>
        body {
            font-family: 'Inter', var(--bs-font-sans-serif);
        }
        pre, code {
            font-family: 'Fira Code', monospace;
            background-color: var(--bs-gray-100);
            padding: 0.2rem 0.4rem;
            border-radius: 0.2rem;
            font-size: 0.875em;
        }
        pre code {
            padding: 0;
            background-color: transparent;
        }
        .hero-section {
            background-color: var(--bs-primary);
            color: white;
            padding: 4rem 0;
            margin-bottom: 2rem;
        }
        .content h2 {
            margin-top: 2rem;
            margin-bottom: 1rem;
        }
        .content h3 {
            margin-top: 1.5rem;
            margin-bottom: 1rem;
        }
        .content p {
            margin-bottom: 1.25rem;
            line-height: 1.7;
        }
        .content ul, .content ol {
            margin-bottom: 1.25rem;
        }
        .content blockquote {
            border-left: 4px solid var(--bs-primary);
            padding-left: 1rem;
            margin-left: 0;
            color: var(--bs-gray-700);
        }
        .tool-card {
            transition: transform 0.2s;
            height: 100%;
        }
        .tool-card:hover {
            transform: translateY(-5px);
        }
        .guide-card {
            border: none;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            transition: transform 0.2s;
        }
        .guide-card:hover {
            transform: translateY(-5px);
        }
        .feature-card {
            border: none;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            transition: transform 0.2s;
            height: 100%;
        }
        .feature-card:hover {
            transform: translateY(-5px);
        }
        .home-hero {
            background: linear-gradient(135deg, var(--bs-primary) 0%, #2563eb 100%);
            padding: 6rem 0;
            margin-bottom: 4rem;
        }
        .home-hero h1 {
            font-size: 3.5rem;
            font-weight: 700;
            margin-bottom: 1.5rem;
        }
        .home-hero p {
            font-size: 1.25rem;
            opacity: 0.9;
        }
    </style>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-CDEBMDP5PL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-CDEBMDP5PL');
</script>
<!-- End Google tag (gtag.js) -->
<!-- DataFa.st Analytics -->
<script
    defer
    data-website-id="682d6fb7b163eb08ed813a43"
    data-domain="llmlogs.com"
    src="https://datafa.st/js/script.js">
</script>
<script async src="https://scripts.simpleanalyticscdn.com/latest.js"></script>
<!-- End DataFa.st Analytics -->
</head>
<body>
<!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-P33Z79C6"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->
    
    <nav class="navbar navbar-expand-lg navbar-light bg-white shadow-sm sticky-top">
        <div class="container">
            <a class="navbar-brand fw-semibold" href="/">LLM Logs</a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="/start-here">Start Here</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="/guides">Guides</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="/tool-reviews">Tool Reviews</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="/blog">Blog</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="https://github.com/mattmerrick/llmseoguide" target="_blank" rel="noopener">GitHub</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>


    <!-- Hero Section -->
    <div class="hero-section">
        <div class="container">
            <nav aria-label="breadcrumb">
                <ol class="breadcrumb mb-4">
                    <li class="breadcrumb-item"><a href="/" class="text-white">Home</a></li>
                    
                    <li class="breadcrumb-item active text-white" aria-current="page">Complete Guide to Open Source LLMs (2025)</li>
                </ol>
            </nav>
            <h1 class="display-4 mb-3">Complete Guide to Open Source LLMs (2025)</h1>
        </div>
    </div>

    <!-- Main Content -->
    <main class="container py-5">
        <div class="row justify-content-center">
            <div class="col-lg-10">
                <div class="content">
                    
            <article>
                <header class="article-header">
                    <h1>Complete Guide to Open Source LLMs (2025)</h1>
                    <div class="post-meta">
                        <time datetime="2025-01-15">Updated: January 15, 2025</time>
                        <span class="reading-time">15 min read</span>
                    </div>
                </header>

                <div class="table-of-contents">
                    <h2>Table of Contents</h2>
                    <ul>
                        <li><a href="#introduction">Introduction to Open Source LLMs</a></li>
                        <li><a href="#why-open-source">Why Open Source LLMs Matter</a></li>
                        <li><a href="#general-purpose">General Purpose Language Models</a></li>
                        <li><a href="#code-specific">Code-Specific Language Models</a></li>
                        <li><a href="#datasets">Training Datasets</a></li>
                        <li><a href="#how-to-choose">How to Choose an Open Source LLM</a></li>
                    </ul>
                </div>

                <section id="introduction">
                    <h2>Introduction to Open Source LLMs</h2>
                    <p>Open source Large Language Models (LLMs) have become increasingly important in the AI landscape, offering researchers and developers free access to powerful language models. This comprehensive directory, based on the excellent work from the <a href="https://github.com/eugeneyan/open-llms" target="_blank" rel="noopener">open-llms GitHub repository</a>, provides an up-to-date overview of available open source language models, their capabilities, and how to try them out.</p>
                </section>

                <section id="why-open-source">
                    <h2>Why Open Source LLMs Matter</h2>
                    <p>Open source LLMs are crucial for several reasons:</p>
                    <ul>
                        <li>Transparency and auditability of AI systems</li>
                        <li>Lower barriers to entry for AI research and development</li>
                        <li>Community-driven improvements and innovations</li>
                        <li>Cost-effective alternatives to proprietary models</li>
                        <li>Freedom to modify and adapt models for specific use cases</li>
                    </ul>
                </section>

                <section id="general-purpose">
                    <h2>General Purpose Language Models</h2>
                    <p>Below is a comprehensive list of general-purpose open source LLMs, ranging from smaller models suitable for specific tasks to large-scale models competing with proprietary alternatives. Each model is listed with its key specifications and, where available, links to try them out directly.</p>
                    
                    <div style="overflow-x: auto;">
                        <table class="llm-table">
                            <thead>
                                <tr>
                                    <th>Model</th>
                                    <th>Release Date</th>
                                    <th>Parameters (B)</th>
                                    <th>Context Length</th>
                                    <th>License</th>
                                    <th>Try it</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>T5</td>
                                    <td>2019/10</td>
                                    <td>0.06 - 11</td>
                                    <td>512</td>
                                    <td>Apache 2.0</td>
                                    <td><a href="https://github.com/slai-labs/get-beam/tree/main/examples/t5" target="_blank">T5-Large</a></td>
                                </tr>
                                <tr>
                                    <td>RWKV 4</td>
                                    <td>2021/08</td>
                                    <td>0.1 - 14</td>
                                    <td>infinity (RNN)</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>GPT-NeoX-20B</td>
                                    <td>2022/04</td>
                                    <td>20</td>
                                    <td>2048</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>YaLM-100B</td>
                                    <td>2022/06</td>
                                    <td>100</td>
                                    <td>1024</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>UL2</td>
                                    <td>2022/10</td>
                                    <td>20</td>
                                    <td>512, 2048</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Bloom</td>
                                    <td>2022/11</td>
                                    <td>176</td>
                                    <td>2048</td>
                                    <td>OpenRAIL-M v1</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>ChatGLM</td>
                                    <td>2023/03</td>
                                    <td>6</td>
                                    <td>2048</td>
                                    <td>Custom Free</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Cerebras-GPT</td>
                                    <td>2023/03</td>
                                    <td>0.111 - 13</td>
                                    <td>2048</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Open Assistant (Pythia family)</td>
                                    <td>2023/03</td>
                                    <td>12</td>
                                    <td>2048</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Pythia</td>
                                    <td>2023/04</td>
                                    <td>0.07 - 12</td>
                                    <td>2048</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Dolly</td>
                                    <td>2023/04</td>
                                    <td>3, 7, 12</td>
                                    <td>2048</td>
                                    <td>MIT</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>StableLM-Alpha</td>
                                    <td>2023/04</td>
                                    <td>3 - 65</td>
                                    <td>4096</td>
                                    <td>CC BY-SA-4.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>FastChat-T5</td>
                                    <td>2023/04</td>
                                    <td>3</td>
                                    <td>512</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>DLite</td>
                                    <td>2023/05</td>
                                    <td>0.124 - 1.5</td>
                                    <td>1024</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>h2oGPT</td>
                                    <td>2023/05</td>
                                    <td>12 - 20</td>
                                    <td>256 - 2048</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>MPT-7B</td>
                                    <td>2023/05</td>
                                    <td>7</td>
                                    <td>84k (ALiBi)</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>RedPajama-INCITE</td>
                                    <td>2023/05</td>
                                    <td>3 - 7</td>
                                    <td>2048</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>OpenLLaMA</td>
                                    <td>2023/05</td>
                                    <td>3, 7</td>
                                    <td>2048</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Falcon</td>
                                    <td>2023/05</td>
                                    <td>7, 40, 180</td>
                                    <td>2048</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>GPT-J-6B</td>
                                    <td>2023/06</td>
                                    <td>6</td>
                                    <td>2048</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>MPT-30B</td>
                                    <td>2023/06</td>
                                    <td>30</td>
                                    <td>8192</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>LLaMA 2</td>
                                    <td>2023/06</td>
                                    <td>7 - 70</td>
                                    <td>4096</td>
                                    <td>Custom Free</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>ChatGLM2</td>
                                    <td>2023/06</td>
                                    <td>6</td>
                                    <td>32k</td>
                                    <td>Custom Free</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>XGen-7B</td>
                                    <td>2023/06</td>
                                    <td>7</td>
                                    <td>4096, 8192</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Jais-13b</td>
                                    <td>2023/08</td>
                                    <td>13</td>
                                    <td>2048</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>OpenHermes</td>
                                    <td>2023/09</td>
                                    <td>7, 13</td>
                                    <td>4096</td>
                                    <td>MIT</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>OpenLM</td>
                                    <td>2023/09</td>
                                    <td>1, 7</td>
                                    <td>2048</td>
                                    <td>MIT</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Mistral 7B</td>
                                    <td>2023/09</td>
                                    <td>7</td>
                                    <td>4096-16K</td>
                                    <td>Apache 2.0</td>
                                    <td><a href="https://huggingface.co/mistralai/Mistral-7B-v0.1" target="_blank">Mistral Transformer</a></td>
                                </tr>
                                <tr>
                                    <td>ChatGLM3</td>
                                    <td>2023/10</td>
                                    <td>6</td>
                                    <td>8192, 32k, 128k</td>
                                    <td>Custom Free</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Skywork</td>
                                    <td>2023/10</td>
                                    <td>13</td>
                                    <td>4096</td>
                                    <td>Custom Free</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Jais-30b</td>
                                    <td>2023/11</td>
                                    <td>30</td>
                                    <td>2048</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Zephyr</td>
                                    <td>2023/11</td>
                                    <td>7</td>
                                    <td>8192</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>DeepSeek</td>
                                    <td>2023/11</td>
                                    <td>7, 67</td>
                                    <td>4096</td>
                                    <td>Custom Free</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Mistral 7B v0.2</td>
                                    <td>2023/12</td>
                                    <td>7</td>
                                    <td>32k</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Mixtral 8x7B v0.1</td>
                                    <td>2023/12</td>
                                    <td>46.7</td>
                                    <td>32k</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>LLM360 Amber</td>
                                    <td>2023/12</td>
                                    <td>6.7</td>
                                    <td>2048</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>SOLAR</td>
                                    <td>2023/12</td>
                                    <td>10.7</td>
                                    <td>4096</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>phi-2</td>
                                    <td>2023/12</td>
                                    <td>2.7</td>
                                    <td>2048</td>
                                    <td>MIT</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>FLOR</td>
                                    <td>2023/12</td>
                                    <td>0.76, 1.3, 6.3</td>
                                    <td>2048</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>RWKV 5 v2</td>
                                    <td>2024/01</td>
                                    <td>0.4, 1.5, 3, 7</td>
                                    <td>unlimited(RNN)</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>OLMo</td>
                                    <td>2024/02</td>
                                    <td>1, 7</td>
                                    <td>2048</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Qwen1.5</td>
                                    <td>2024/02</td>
                                    <td>7, 14, 72</td>
                                    <td>32k</td>
                                    <td>Custom Free</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>LWM</td>
                                    <td>2024/02</td>
                                    <td>7</td>
                                    <td>128k-1M</td>
                                    <td>LLaMA 2 license</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Jais-30b v3</td>
                                    <td>2024/03</td>
                                    <td>30</td>
                                    <td>8192</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Gemma</td>
                                    <td>2024/02</td>
                                    <td>2-7</td>
                                    <td>8192</td>
                                    <td>Gemma Terms of Use</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Grok-1</td>
                                    <td>2024/03</td>
                                    <td>314</td>
                                    <td>8192</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Qwen1.5 MoE</td>
                                    <td>2024/03</td>
                                    <td>14.3</td>
                                    <td>8192</td>
                                    <td>Custom Free</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Jamba 0.1</td>
                                    <td>2024/03</td>
                                    <td>52</td>
                                    <td>256k</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Qwen1.5 32B</td>
                                    <td>2024/04</td>
                                    <td>32</td>
                                    <td>32k</td>
                                    <td>Custom Free</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Mamba-7B</td>
                                    <td>2024/04</td>
                                    <td>7</td>
                                    <td>unlimited(RNN)</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Mixtral8x22B v0.1</td>
                                    <td>2024/04</td>
                                    <td>141</td>
                                    <td>64k</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Llama 3</td>
                                    <td>2024/04</td>
                                    <td>8, 70</td>
                                    <td>8192</td>
                                    <td>Meta Llama 3 License</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Phi-3 Mini</td>
                                    <td>2024/04</td>
                                    <td>3.8</td>
                                    <td>4096, 128k</td>
                                    <td>MIT</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>OpenELM</td>
                                    <td>2024/04</td>
                                    <td>0.27, 0.45, 1.1, 3</td>
                                    <td>2048</td>
                                    <td>Custom open license</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Snowflake Arctic</td>
                                    <td>2024/04</td>
                                    <td>480</td>
                                    <td>4096</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Qwen1.5 110B</td>
                                    <td>2024/04</td>
                                    <td>110</td>
                                    <td>32k</td>
                                    <td>Custom Free</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>RWKV 6 v2.1</td>
                                    <td>2024/05</td>
                                    <td>1.6, 3, 7</td>
                                    <td>unlimited(RNN)</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>DeepSeek-V2</td>
                                    <td>2024/05</td>
                                    <td>236</td>
                                    <td>128k</td>
                                    <td>Custom Free</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Fugaku-LLM</td>
                                    <td>2024/05</td>
                                    <td>13</td>
                                    <td>2048</td>
                                    <td>Custom Free</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Falcon 2</td>
                                    <td>2024/05</td>
                                    <td>11</td>
                                    <td>8192</td>
                                    <td>Custom Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Yi-1.5</td>
                                    <td>2024/05</td>
                                    <td>6, 9, 34</td>
                                    <td>4096</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>DeepSeek-V2-Lite</td>
                                    <td>2024/05</td>
                                    <td>16</td>
                                    <td>32k</td>
                                    <td>Custom Free</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Phi-3 small/medium</td>
                                    <td>2024/05</td>
                                    <td>7, 14</td>
                                    <td>4096, 128k</td>
                                    <td>MIT</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Phi-4</td>
                                    <td>2024/12</td>
                                    <td>14</td>
                                    <td>4096</td>
                                    <td>MIT</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>YuLan-Mini</td>
                                    <td>2024/12</td>
                                    <td>14</td>
                                    <td>28672</td>
                                    <td>MIT</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Selene Mini</td>
                                    <td>2025/01</td>
                                    <td>8</td>
                                    <td>128K</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </section>

                <section id="code-specific">
                    <h2>Code-Specific Language Models</h2>
                    <p>Code-specific LLMs are specialized models trained specifically for programming tasks. These models excel at code completion, generation, and understanding programming languages. Here's a curated list of open source code-specific models:</p>

                    <div style="overflow-x: auto;">
                        <table class="llm-table">
                            <thead>
                                <tr>
                                    <th>Model</th>
                                    <th>Release Date</th>
                                    <th>Parameters (B)</th>
                                    <th>Context Length</th>
                                    <th>License</th>
                                    <th>Try it</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>SantaCoder</td>
                                    <td>2023/01</td>
                                    <td>1.1</td>
                                    <td>2048</td>
                                    <td>OpenRAIL-M v1</td>
                                    <td><a href="https://huggingface.co/bigcode/santacoder" target="_blank">SantaCoder</a></td>
                                </tr>
                                <tr>
                                    <td>CodeGen2</td>
                                    <td>2023/04</td>
                                    <td>1 - 16</td>
                                    <td>2048</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>StarCoder</td>
                                    <td>2023/05</td>
                                    <td>1.1-15</td>
                                    <td>8192</td>
                                    <td>OpenRAIL-M v1</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>StarChat Alpha</td>
                                    <td>2023/05</td>
                                    <td>16</td>
                                    <td>8192</td>
                                    <td>OpenRAIL-M v1</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Replit Code</td>
                                    <td>2023/05</td>
                                    <td>2.7</td>
                                    <td>infinity (ALiBi)</td>
                                    <td>CC BY-SA-4.0</td>
                                    <td><a href="https://github.com/slai-labs/get-beam/tree/main/examples/replit-code" target="_blank">Replit-Code-v1-3B</a></td>
                                </tr>
                                <tr>
                                    <td>CodeT5+</td>
                                    <td>2023/05</td>
                                    <td>0.22 - 16</td>
                                    <td>512</td>
                                    <td>BSD-3-Clause</td>
                                    <td><a href="https://github.com/slai-labs/get-beam/tree/main/examples/codeT5%2B" target="_blank">Codet5+-6B</a></td>
                                </tr>
                                <tr>
                                    <td>XGen-7B</td>
                                    <td>2023/06</td>
                                    <td>7</td>
                                    <td>8192</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>CodeGen2.5</td>
                                    <td>2023/07</td>
                                    <td>7</td>
                                    <td>2048</td>
                                    <td>Apache 2.0</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>DeciCoder-1B</td>
                                    <td>2023/08</td>
                                    <td>1.1</td>
                                    <td>2048</td>
                                    <td>Apache 2.0</td>
                                    <td><a href="https://huggingface.co/spaces/Deci/DeciCoder-Demo" target="_blank">DeciCoder Demo</a></td>
                                </tr>
                                <tr>
                                    <td>Code Llama</td>
                                    <td>2023/08</td>
                                    <td>7 - 34</td>
                                    <td>4096</td>
                                    <td>Custom Free</td>
                                    <td><a href="https://huggingface.co/blog/codellama" target="_blank">HuggingChat</a></td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </section>

                <section id="datasets">
                    <h2>Training Datasets</h2>
                    <p>The quality and size of training data are crucial factors in LLM performance. Here are the major open source datasets used for training and fine-tuning these models:</p>

                    <div style="overflow-x: auto;">
                        <table class="llm-table">
                            <thead>
                                <tr>
                                    <th>Dataset</th>
                                    <th>Release Date</th>
                                    <th>Tokens (T)</th>
                                    <th>License</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>RedPajama</td>
                                    <td>2023/04</td>
                                    <td>1.2</td>
                                    <td>Apache 2.0</td>
                                </tr>
                                <tr>
                                    <td>starcoderdata</td>
                                    <td>2023/05</td>
                                    <td>0.25</td>
                                    <td>Apache 2.0</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </section>

                <section id="how-to-choose">
                    <h2>How to Choose an Open Source LLM</h2>
                    <p>When selecting an open source LLM for your project, consider these key factors:</p>
                    <ul>
                        <li><strong>Model Size:</strong> Larger models (more parameters) generally perform better but require more computational resources</li>
                        <li><strong>Context Length:</strong> Longer context windows allow the model to consider more text but increase memory usage</li>
                        <li><strong>License:</strong> Ensure the model's license aligns with your intended use case</li>
                        <li><strong>Community Support:</strong> Active communities can provide better support and ongoing improvements</li>
                        <li><strong>Hardware Requirements:</strong> Consider your available computational resources</li>
                    </ul>
                </section>

                <div class="attribution">
                    <p>Data sourced from the <a href="https://github.com/eugeneyan/open-llms" target="_blank" rel="noopener">open-llms GitHub repository</a>. Last updated: January 2025.</p>
                </div>

                <div class="share-section">
                    <h3>Share this Guide</h3>
                    <div class="share-buttons">
                        <button class="share-button" onclick="copyToClipboard(window.location.href)">Copy Link</button>
                        <a href="https://twitter.com/intent/tweet?url=https://llmlogs.com/blog/open-llms.html&amp;text=Complete Guide to Open Source LLMs (2025)" class="social-share twitter" target="_blank" rel="noopener">Share on Twitter</a>
                        <a href="https://www.linkedin.com/shareArticle?url=https://llmlogs.com/blog/open-llms.html&amp;title=Complete Guide to Open Source LLMs (2025)" class="social-share linkedin" target="_blank" rel="noopener">Share on LinkedIn</a>
                    </div>
                </div>
            </article>
        
                </div>
            </div>
        </div>
    </main>

    
    <footer class="bg-white py-5 mt-5">
        <div class="container">
            <div class="row justify-content-center text-center">
                <div class="col-md-8">
                    <div class="d-flex flex-column flex-md-row justify-content-center gap-4 mb-4">
                        <a href="/" class="text-muted text-decoration-none">Home</a>
                        <a href="/guides" class="text-muted text-decoration-none">Guides</a>
                        <a href="/tools" class="text-muted text-decoration-none">Tools</a>
                        <a href="/blog" class="text-muted text-decoration-none">Blog</a>
                        <a href="https://github.com/mattmerrick/llmseoguide" target="_blank" rel="noopener" class="text-muted text-decoration-none">GitHub</a>
                    </div>
                    <p class="text-muted small mb-0">&copy; 2025 LLM Logs. All rights reserved.</p>
                </div>
            </div>
        </div>
    </footer>

    <!-- Bootstrap Bundle with Popper -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>

</body>
</html>


